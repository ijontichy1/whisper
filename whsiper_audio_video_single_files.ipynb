{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gu-tBa8VigYzEvAAxFvi3ae94L3cMO24",
      "authorship_tag": "ABX9TyOAZ6nWb+V9KqRQIxS8y8O4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ijontichy1/whisper/blob/main/whsiper_audio_video_single_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "![picture](https://drive.google.com/uc?export=view&id=15xQaGVrJej6UIPjfAB-QVWXLWVChPJSt)<br>\n",
        "נכתב על ידי [עודד זרחיה](mailto:odedzarchia@tauex.tau.ac.il)<br>\n",
        "[הספרייה המרכזית ע\"ש סוראסקי](https://cenlib.tau.ac.il/) | [אוניברסיטת תל אביב](https://tau.ac.il/)"
      ],
      "metadata": {
        "id": "oQpkmckW3kIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">1. תמלול קבצי אודיו/וידאו באמצעות Whisper </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "[Whisper](https://openai.com/blog/whisper/) הוא מודל לזיהוי דיבור מבית [OpenAI](https://https://openai.com/) הזמין לציבור הרחב בקוד פתוח. מודל זה אומן על יותר מ-680 אלף שעות של שיחות באנגלית ובשפות רבות אחרות – בהן גם עברית.\n",
        "\n",
        "מחברת זו תדריך אתכם בתמלול קטעי וידאו/אודיו באמצעות Whisper. תוכלו להשתמש במחברת כפי שהיא כדי לאחסן את קבצי האודיו/וידאו ואת התמליל ב-Google Drive.\n",
        "\n",
        "לתשומת לבכם - השימוש במחברת זו ובמודל של Whisper חופשי לחלוטין וללא שום עלות. בנוסף, אין הגבלה על אורך קטעי הוידאו/אודיו שניתן לתמלל באמצעות Whisper."
      ],
      "metadata": {
        "id": "TsYo7x7KhucD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">2. בדוק את סוג המעבד הגרפי (GPU) </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "סוג [המעבד הגרפי](https://https://he.wikipedia.org/wiki/%D7%9E%D7%A2%D7%91%D7%93_%D7%92%D7%A8%D7%A4%D7%99) **(GPU - Graphics Processing Unit)** שאתם מקבלים ב-Google Colab מגדיר את המהירות שבה קטע הוידאו/אודיו יתומלל. ככל שמספר [הפלופס](https://https://he.wikipedia.org/wiki/FLOPS) **(FLOPS - Floating Point Operations Per Second, פעולות נקודות צפות לשנייה)** גבוה יותר, כך התמלול מהיר יותר. יחד עם זאת, גם המעבד הגרפי החלש ביותר ב-Colab מסוגל להריץ כל מודל של Whisper. יש לוודא כי בחרתם ב-GPU כמאיץ חומרה עבור מחברת זו (Runtime → Change runtime type → Hardware accelerator).\n",
        "</div>\n",
        "\n",
        "|  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "|:------:|:----------:|:--------------:|:------------------:|\n",
        "|  T4    |    16 GB   |       8.1      |         Free       |\n",
        "| P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "| V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |"
      ],
      "metadata": {
        "id": "5jTJEI2WX8g8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לוודא את סוג המעבד הגרפי שהוקצה עבור מחברת זו. אפסו את ה-runtime של המחברת אם ברצונכם לקבל מעבד גרפי אחר (Runtime → Restart runtime)."
      ],
      "metadata": {
        "id": "Dpb-if7dtKMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check gpu type\n",
        "!nvidia-smi -L\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygyW5Wjd2Xqz",
        "outputId": "e67dd263-7033-46f9-919a-b6e122f245ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-e7b6cf6e-8cb3-43a5-2ae5-3d5d917a522c)\n",
            "Thu Feb  2 10:11:45 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0    29W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">3. התקנת ספריות </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להוריד ולהתקין את הספריות הנחוצות לפעולת התמלול:\n",
        "\n",
        "1.   [whisper](https://https://github.com/openai/whisper) (עבור תמלול)\n",
        "2.   [moviepy](https://https://pypi.org/project/moviepy/) (עבור חילוץ אודיו)\n",
        "3.   [imageio](https://https://pypi.org/project/imageio/) (נדרש עבור moviepy)\n",
        "4.   [jiwer](https://https://pypi.org/project/jiwer/) (עבור בדיקת WER)"
      ],
      "metadata": {
        "id": "pgXqU0Fs1310"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install moviepy\n",
        "!pip3 install imageio==2.4.1\n",
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "xP_lbfCa2gzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "678c8e82-a4df-45cd-f593-3d8789720a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f1jbikut\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f1jbikut\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->openai-whisper==20230124) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179424 sha256=5e9b3415080f4bacebd27042d8814fc85dd34aafb3b04c5219ba32e547a374ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n7hatjs5/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.0 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.8/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.64.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from moviepy) (1.21.6)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.8/dist-packages (from moviepy) (2.9.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.4.1\n",
            "  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from imageio==2.4.1) (7.1.2)\n",
            "Building wheels for collected packages: imageio\n",
            "  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303886 sha256=a2f4ed5e7fb4966946f0149b1fb33aed7f15fb46cb040ffe03718b4340aee222\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/7b/04/4d8d56f1d503e5c404f0de6018c0cfa592c71588a39b49e002\n",
            "Successfully built imageio\n",
            "Installing collected packages: imageio\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
            "Collecting levenshtein==0.20.2\n",
            "  Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein, jiwer\n",
            "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">4. ייבוא ספריות </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לייבא את הספריות הנדרשות עבור פעולת התמלול."
      ],
      "metadata": {
        "id": "aG9xCsNbjNUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import moviepy.editor\n",
        "from jiwer import wer"
      ],
      "metadata": {
        "id": "CODmLFMC2_Q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5e1cfb-c8eb-4205-957d-768ba9b701b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2482176/45929032 bytes (5.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b4603904/45929032 bytes (10.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b6627328/45929032 bytes (14.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b9101312/45929032 bytes (19.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11059200/45929032 bytes (24.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b13221888/45929032 bytes (28.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15269888/45929032 bytes (33.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19406848/45929032 bytes (42.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23691264/45929032 bytes (51.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28033024/45929032 bytes (61.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32251904/45929032 bytes (70.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b36577280/45929032 bytes (79.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b40951808/45929032 bytes (89.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45211648/45929032 bytes (98.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">5. חיבור ל-Google Drive </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי להתחבר ל-Google Drive האישי שלכם. כדי לראות את הקבצים שלכם פתחו את סייר הקבצים בתפריט השמאלי."
      ],
      "metadata": {
        "id": "s976fYrHf7QA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EnzjKLvyzcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bace7c-6ab8-4939-915e-58f57772929d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">6. פתיחת קטע הוידאו עם moviepy </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "טענו קובץ וידאו מ-Google Drive באמצעות moviepy. שנו את הנתיב כדי לטעון את הקובץ שלכם (אתרו את הקובץ בסייר הקבצים, לחצו על הכפתור הימני בעכבר ← Copy path)."
      ],
      "metadata": {
        "id": "HxNrm8eNmCDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video = moviepy.editor.VideoFileClip(\"/content/gdrive/MyDrive/tamar/GMT20200913-121425_------_avo_1280x720.mp4\")"
      ],
      "metadata": {
        "id": "1Qzqa-hQ38aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">7. חילוץ שכבת אודיו </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לחלץ את שכבת האודיו מקובץ הוידאו שלכם באמצעות moviepy וכדי לשמור אותה כקובץ נפרד ב-Google Drive שלכם."
      ],
      "metadata": {
        "id": "s_4HY_I1mU1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = video.audio\n",
        "audio.write_audiofile(\"/content/gdrive/MyDrive/tamar1.mp3\")"
      ],
      "metadata": {
        "id": "4fs0IJtU4Cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085c1953-1330-4853-abda-e4db4691e6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Writing audio in /content/gdrive/MyDrive/tamar1.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55736/55736 [01:01<00:00, 911.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MoviePy] Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">8. תמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לתמלל את קובץ האודיו שחילצנו באמצעות Whisper. יושם לב כי אנו משתמשים במודל הגדול ביותר (large) שהוא המדויק ביותר לעברית. עבור שפות אחרות ניתן להחליף בין סוגי המודלים השונים בהתאם למפורט בטבלה הבאה:\n",
        "</div>\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   2870 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n"
      ],
      "metadata": {
        "id": "FXn6PYvKnkue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(\"/content/gdrive/MyDrive/tamar/tamar1.mp3\", verbose = False)"
      ],
      "metadata": {
        "id": "6GA_c_GN4hye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57da68c-0186-4e9f-aa88-6132fd7b1cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.87G/2.87G [00:22<00:00, 136MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected language: Hebrew\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 252768/252768 [11:21<00:00, 370.76frames/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">9. שמירת התמלול </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הריצו את התא הבא כדי לשמור את התמלול ב-Google Drive שלכם כקובץ טקסט."
      ],
      "metadata": {
        "id": "wipGaWwzntPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/gdrive/MyDrive/tamar/tamar1.txt', 'w') as f:\n",
        "    f.write(result[\"text\"])"
      ],
      "metadata": {
        "id": "30kYO2zGnb_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **<div style=\"direction:rtl\" dir=\"rtl\">10. בדיקת WER (אופציונלי) </div>**\n",
        "<div style=\"direction:rtl\" dir=\"rtl\">\n",
        "\n",
        "הרצת התאים הבאים תאפשר לכם להעריך את הדיוק של התמלול של Whisper במספר שלבים, וזאת במידה ויש ברשותכם את קובץ התמלול המקורי:\n",
        "\n",
        "\n",
        "\n",
        "1.   נירמול פלט התמלול של Whisper וקובץ התמלול המקורי ([Ground Truth](https://https://en.wikipedia.org/wiki/Ground_truth)) - הסרת סימני פיסוק, רווחים מיותרים, קפיטליזציה וכו'.\n",
        "2.   השוואה בין שני הקבצים וחישוב אחוז השגיאות בהתאם למדד [Word Error Rate](https://https://en.wikipedia.org/wiki/Word_error_rate) - באמצעות ספריית jiwer."
      ],
      "metadata": {
        "id": "Fu4T6I4unZOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize result\n",
        "import string\n",
        "heb_transcription_norm = open('/content/gdrive/MyDrive/hebrew_large.txt', 'r').read().lower().translate(str.maketrans('', '', string.punctuation))\n",
        "print(heb_transcription_norm)"
      ],
      "metadata": {
        "id": "hZH75qr1eQe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize ground truth\n",
        "heb_ground_truth_norm = open('/content/gdrive/MyDrive/gt.txt', 'r').read().lower().strip().translate(str.maketrans('', '', string.punctuation))\n",
        "print(heb_ground_truth_norm)"
      ],
      "metadata": {
        "id": "JiJrffps20B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate WER\n",
        "ground_truth = heb_ground_truth_norm\n",
        "hypothesis = heb_transcription_norm\n",
        "\n",
        "error = wer(ground_truth, hypothesis)\n",
        "print(error)"
      ],
      "metadata": {
        "id": "kFc5CTcPd_hM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}